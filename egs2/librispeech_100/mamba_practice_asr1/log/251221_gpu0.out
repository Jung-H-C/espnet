nohup: ignoring input
==================================================================================
Training All Models from gpu_id_0_config.txt Sequentially
Using GPU 0
==================================================================================

Warning: Skipping line with empty num_blocks: Block   Params  N_of_Blocks Total_Params
==================================================================================
Model 1/70: Training
==================================================================================
Block Structure: B
Module Config (list format): ['B']
Block Params (M): 0.482
Number of Blocks: 45
Total Params (M): 21.690
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_B_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B']
  Applied to 45 blocks
YAML file updated successfully.
2025-12-20T15:33:36 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_B_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-20T15:33:37 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-20T15:33:37 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-20T15:33:37 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_B_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-20T15:33:37 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_B_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-20T15:33:37 (asr.sh:1451:main) Use ESPnet trainer
2025-12-20 15:33:37,187 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_B_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_B_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_B_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_B_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-20 15:33:37,203 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_B_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-21T03:25:40 (asr.sh:1842:main) Successfully finished. [elapsed=42724s]

✓ Model 1 (B) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_B_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_B_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 2/70: Training
==================================================================================
Block Structure: BBBC
Module Config (list format): ['B','B','B','C']
Block Params (M): 1.652
Number of Blocks: 13
Total Params (M): 21.476
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'B', 'C']
  Applied to 13 blocks
YAML file updated successfully.
2025-12-21T03:25:40 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-21T03:25:40 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-21T03:25:40 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-21T03:25:40 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-21T03:25:40 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-21T03:25:40 (asr.sh:1451:main) Use ESPnet trainer
2025-12-21 03:25:40,609 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-21 03:25:40,625 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-21T20:02:06 (asr.sh:1842:main) Successfully finished. [elapsed=59786s]

✓ Model 2 (BBBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 3/70: Training
==================================================================================
Block Structure: BBBCF
Module Config (list format): ['B','B','B','C','F']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBCF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'B', 'C', 'F']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-21T20:02:06 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBCF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-21T20:02:06 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-21T20:02:06 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-21T20:02:06 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBCF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-21T20:02:06 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBCF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-21T20:02:06 (asr.sh:1451:main) Use ESPnet trainer
2025-12-21 20:02:06,883 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBCF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBCF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBCF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBCF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-21 20:02:06,900 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBCF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-22T09:29:02 (asr.sh:1842:main) Successfully finished. [elapsed=48416s]

✓ Model 3 (BBBCF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 4/70: Training
==================================================================================
Block Structure: BBBF
Module Config (list format): ['B','B','B','F']
Block Params (M): 1.972
Number of Blocks: 11
Total Params (M): 21.692
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'B', 'F']
  Applied to 11 blocks
YAML file updated successfully.
2025-12-22T09:29:02 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-22T09:29:02 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-22T09:29:02 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-22T09:29:02 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-22T09:29:02 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-22T09:29:02 (asr.sh:1451:main) Use ESPnet trainer
2025-12-22 09:29:02,641 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-22 09:29:02,657 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-22T21:13:28 (asr.sh:1842:main) Successfully finished. [elapsed=42266s]

✓ Model 4 (BBBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 5/70: Training
==================================================================================
Block Structure: BBBFC
Module Config (list format): ['B','B','B','F','C']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'B', 'F', 'C']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-22T21:13:28 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-22T21:13:28 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-22T21:13:28 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-22T21:13:28 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-22T21:13:28 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-22T21:13:28 (asr.sh:1451:main) Use ESPnet trainer
2025-12-22 21:13:28,975 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-22 21:13:28,992 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-23T09:09:27 (asr.sh:1842:main) Successfully finished. [elapsed=42959s]

✓ Model 5 (BBBFC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 6/70: Training
==================================================================================
Block Structure: BBBFF
Module Config (list format): ['B','B','B','F','F']
Block Params (M): 2.498
Number of Blocks: 9
Total Params (M): 22.482
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'B', 'F', 'F']
  Applied to 9 blocks
YAML file updated successfully.
2025-12-23T09:09:27 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-23T09:09:27 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-23T09:09:27 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-23T09:09:27 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-23T09:09:27 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-23T09:09:27 (asr.sh:1451:main) Use ESPnet trainer
2025-12-23 09:09:28,115 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-23 09:09:28,131 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-23T10:21:12 (asr.sh:1842:main) Successfully finished. [elapsed=4305s]

✓ Model 6 (BBBFF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBBFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 7/70: Training
==================================================================================
Block Structure: BBC
Module Config (list format): ['B','B','C']
Block Params (M): 1.170
Number of Blocks: 18
Total Params (M): 21.060
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'C']
  Applied to 18 blocks
YAML file updated successfully.
2025-12-23T10:21:12 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-23T10:21:12 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-23T10:21:12 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-23T10:21:12 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-23T10:21:12 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-23T10:21:12 (asr.sh:1451:main) Use ESPnet trainer
2025-12-23 10:21:12,738 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-23 10:21:12,754 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-23T22:40:46 (asr.sh:1842:main) Successfully finished. [elapsed=44374s]

✓ Model 7 (BBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 8/70: Training
==================================================================================
Block Structure: BBCB
Module Config (list format): ['B','B','C','B']
Block Params (M): 1.652
Number of Blocks: 13
Total Params (M): 21.476
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'C', 'B']
  Applied to 13 blocks
YAML file updated successfully.
2025-12-23T22:40:47 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-23T22:40:47 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-23T22:40:47 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-23T22:40:47 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-23T22:40:47 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-23T22:40:47 (asr.sh:1451:main) Use ESPnet trainer
2025-12-23 22:40:47,439 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-23 22:40:47,455 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-24T14:23:53 (asr.sh:1842:main) Successfully finished. [elapsed=56586s]

✓ Model 8 (BBCB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 9/70: Training
==================================================================================
Block Structure: BBCBC
Module Config (list format): ['B','B','C','B','C']
Block Params (M): 1.858
Number of Blocks: 12
Total Params (M): 22.296
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'C', 'B', 'C']
  Applied to 12 blocks
YAML file updated successfully.
2025-12-24T14:23:53 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-24T14:23:53 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-24T14:23:53 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-24T14:23:53 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-24T14:23:53 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-24T14:23:53 (asr.sh:1451:main) Use ESPnet trainer
2025-12-24 14:23:53,597 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-24 14:23:53,628 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-25T02:02:00 (asr.sh:1842:main) Successfully finished. [elapsed=41887s]

✓ Model 9 (BBCBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 10/70: Training
==================================================================================
Block Structure: BBCBF
Module Config (list format): ['B','B','C','B','F']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'C', 'B', 'F']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-25T02:02:00 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-25T02:02:00 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-25T02:02:00 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-25T02:02:00 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-25T02:02:00 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-25T02:02:00 (asr.sh:1451:main) Use ESPnet trainer
2025-12-25 02:02:00,759 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-25 02:02:00,775 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-25T15:28:28 (asr.sh:1842:main) Successfully finished. [elapsed=48388s]

✓ Model 10 (BBCBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 11/70: Training
==================================================================================
Block Structure: BBCF
Module Config (list format): ['B','B','C','F']
Block Params (M): 1.696
Number of Blocks: 13
Total Params (M): 22.048
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'C', 'F']
  Applied to 13 blocks
YAML file updated successfully.
2025-12-25T15:28:28 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-25T15:28:28 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-25T15:28:28 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-25T15:28:28 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-25T15:28:28 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-25T15:28:28 (asr.sh:1451:main) Use ESPnet trainer
2025-12-25 15:28:28,717 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-25 15:28:28,733 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-26T05:36:11 (asr.sh:1842:main) Successfully finished. [elapsed=50863s]

✓ Model 11 (BBCF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 12/70: Training
==================================================================================
Block Structure: BBCFB
Module Config (list format): ['B','B','C','F','B']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'C', 'F', 'B']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-26T05:36:12 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-26T05:36:13 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-26T05:36:13 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-26T05:36:13 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-26T05:36:13 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-26T05:36:13 (asr.sh:1451:main) Use ESPnet trainer
2025-12-26 05:36:13,337 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-26 05:36:13,388 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-26T17:06:11 (asr.sh:1842:main) Successfully finished. [elapsed=41399s]

✓ Model 12 (BBCFB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 13/70: Training
==================================================================================
Block Structure: BBCFC
Module Config (list format): ['B','B','C','F','C']
Block Params (M): 1.902
Number of Blocks: 11
Total Params (M): 20.922
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'C', 'F', 'C']
  Applied to 11 blocks
YAML file updated successfully.
2025-12-26T17:06:11 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-26T17:06:12 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-26T17:06:12 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-26T17:06:12 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-26T17:06:12 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-26T17:06:12 (asr.sh:1451:main) Use ESPnet trainer
2025-12-26 17:06:12,917 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-26 17:06:12,951 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-27T05:18:07 (asr.sh:1842:main) Successfully finished. [elapsed=43916s]

✓ Model 13 (BBCFC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 14/70: Training
==================================================================================
Block Structure: BBCFF
Module Config (list format): ['B','B','C','F','F']
Block Params (M): 2.222
Number of Blocks: 10
Total Params (M): 22.220
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'C', 'F', 'F']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-27T05:18:07 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-27T05:18:08 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-27T05:18:08 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-27T05:18:08 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-27T05:18:08 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-27T05:18:08 (asr.sh:1451:main) Use ESPnet trainer
2025-12-27 05:18:09,060 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-27 05:18:09,099 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-27T15:19:02 (asr.sh:1842:main) Successfully finished. [elapsed=36055s]

✓ Model 14 (BBCFF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBCFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 15/70: Training
==================================================================================
Block Structure: BBF
Module Config (list format): ['B','B','F']
Block Params (M): 1.490
Number of Blocks: 14
Total Params (M): 20.860
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'F']
  Applied to 14 blocks
YAML file updated successfully.
2025-12-27T15:19:02 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-27T15:19:04 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-27T15:19:04 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-27T15:19:04 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-27T15:19:04 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-27T15:19:04 (asr.sh:1451:main) Use ESPnet trainer
2025-12-27 15:19:04,367 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-27 15:19:04,390 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-28T01:27:53 (asr.sh:1842:main) Successfully finished. [elapsed=36531s]

✓ Model 15 (BBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 16/70: Training
==================================================================================
Block Structure: BBFB
Module Config (list format): ['B','B','F','B']
Block Params (M): 1.972
Number of Blocks: 11
Total Params (M): 21.692
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'F', 'B']
  Applied to 11 blocks
YAML file updated successfully.
2025-12-28T01:27:53 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-28T01:27:54 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-28T01:27:54 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-28T01:27:54 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-28T01:27:54 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-28T01:27:54 (asr.sh:1451:main) Use ESPnet trainer
2025-12-28 01:27:54,397 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-28 01:27:54,435 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-28T17:53:18 (asr.sh:1842:main) Successfully finished. [elapsed=59125s]

✓ Model 16 (BBFB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 17/70: Training
==================================================================================
Block Structure: BBFBC
Module Config (list format): ['B','B','F','B','C']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'F', 'B', 'C']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-28T17:53:19 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-28T17:53:20 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-28T17:53:20 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-28T17:53:20 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-28T17:53:20 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-28T17:53:20 (asr.sh:1451:main) Use ESPnet trainer
2025-12-28 17:53:20,346 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-28 17:53:20,384 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-29T07:12:10 (asr.sh:1842:main) Successfully finished. [elapsed=47931s]

✓ Model 17 (BBFBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 18/70: Training
==================================================================================
Block Structure: BBFBF
Module Config (list format): ['B','B','F','B','F']
Block Params (M): 2.498
Number of Blocks: 9
Total Params (M): 22.482
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'F', 'B', 'F']
  Applied to 9 blocks
YAML file updated successfully.
2025-12-29T07:12:11 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-29T07:12:12 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-29T07:12:12 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-29T07:12:12 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-29T07:12:12 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-29T07:12:12 (asr.sh:1451:main) Use ESPnet trainer
2025-12-29 07:12:12,386 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-29 07:12:12,423 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-29T08:32:25 (asr.sh:1842:main) Successfully finished. [elapsed=4814s]

✓ Model 18 (BBFBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 19/70: Training
==================================================================================
Block Structure: BBFC
Module Config (list format): ['B','B','F','C']
Block Params (M): 1.696
Number of Blocks: 13
Total Params (M): 22.048
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'F', 'C']
  Applied to 13 blocks
YAML file updated successfully.
2025-12-29T08:32:26 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-29T08:32:27 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-29T08:32:27 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-29T08:32:27 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-29T08:32:27 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-29T08:32:27 (asr.sh:1451:main) Use ESPnet trainer
2025-12-29 08:32:27,636 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-29 08:32:27,675 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-29T18:18:36 (asr.sh:1842:main) Successfully finished. [elapsed=35170s]

✓ Model 19 (BBFC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 20/70: Training
==================================================================================
Block Structure: BBFCB
Module Config (list format): ['B','B','F','C','B']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'F', 'C', 'B']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-29T18:18:37 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-29T18:18:38 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-29T18:18:38 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-29T18:18:38 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-29T18:18:38 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-29T18:18:38 (asr.sh:1451:main) Use ESPnet trainer
2025-12-29 18:18:38,765 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-29 18:18:38,807 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-30T08:47:57 (asr.sh:1842:main) Successfully finished. [elapsed=52160s]

✓ Model 20 (BBFCB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 21/70: Training
==================================================================================
Block Structure: BBFCF
Module Config (list format): ['B','B','F','C','F']
Block Params (M): 2.222
Number of Blocks: 10
Total Params (M): 22.220
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'F', 'C', 'F']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-30T08:47:58 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-30T08:47:59 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-30T08:47:59 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-30T08:47:59 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-30T08:47:59 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-30T08:47:59 (asr.sh:1451:main) Use ESPnet trainer
2025-12-30 08:47:59,430 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-30 08:47:59,467 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-30T18:05:53 (asr.sh:1842:main) Successfully finished. [elapsed=33475s]

✓ Model 21 (BBFCF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 22/70: Training
==================================================================================
Block Structure: BBFF
Module Config (list format): ['B','B','F','F']
Block Params (M): 2.016
Number of Blocks: 11
Total Params (M): 22.176
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'F', 'F']
  Applied to 11 blocks
YAML file updated successfully.
2025-12-30T18:05:54 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-30T18:05:55 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-30T18:05:55 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-30T18:05:55 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-30T18:05:55 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-30T18:05:55 (asr.sh:1451:main) Use ESPnet trainer
2025-12-30 18:05:55,413 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-30 18:05:55,436 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-31T07:05:06 (asr.sh:1842:main) Successfully finished. [elapsed=46752s]

✓ Model 22 (BBFF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 23/70: Training
==================================================================================
Block Structure: BBFFB
Module Config (list format): ['B','B','F','F','B']
Block Params (M): 2.498
Number of Blocks: 9
Total Params (M): 22.482
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'F', 'F', 'B']
  Applied to 9 blocks
YAML file updated successfully.
2025-12-31T07:05:06 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-31T07:05:07 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-31T07:05:07 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-31T07:05:07 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-31T07:05:07 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-31T07:05:07 (asr.sh:1451:main) Use ESPnet trainer
2025-12-31 07:05:07,891 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-31 07:05:07,940 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-31T08:59:47 (asr.sh:1842:main) Successfully finished. [elapsed=6881s]

✓ Model 23 (BBFFB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 5 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 24/70: Training
==================================================================================
Block Structure: BBFFC
Module Config (list format): ['B','B','F','F','C']
Block Params (M): 2.222
Number of Blocks: 10
Total Params (M): 22.220
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'F', 'F', 'C']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-31T08:59:48 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-31T08:59:49 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-31T08:59:49 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-31T08:59:49 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-31T08:59:49 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-31T08:59:49 (asr.sh:1451:main) Use ESPnet trainer
2025-12-31 08:59:49,874 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-31 08:59:49,911 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-31T19:01:45 (asr.sh:1842:main) Successfully finished. [elapsed=36117s]

✓ Model 24 (BBFFC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 25/70: Training
==================================================================================
Block Structure: BBFFF
Module Config (list format): ['B','B','F','F','F']
Block Params (M): 2.542
Number of Blocks: 8
Total Params (M): 20.336
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'B', 'F', 'F', 'F']
  Applied to 8 blocks
YAML file updated successfully.
2025-12-31T19:01:46 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-31T19:01:46 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-31T19:01:47 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-31T19:01:47 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-31T19:01:47 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-31T19:01:47 (asr.sh:1451:main) Use ESPnet trainer
2025-12-31 19:01:47,313 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-31 19:01:47,348 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-01T04:15:18 (asr.sh:1842:main) Successfully finished. [elapsed=33213s]

✓ Model 25 (BBFFF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BBFFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 26/70: Training
==================================================================================
Block Structure: BC
Module Config (list format): ['B','C']
Block Params (M): 0.688
Number of Blocks: 31
Total Params (M): 21.328
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C']
  Applied to 31 blocks
YAML file updated successfully.
2026-01-01T04:15:18 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-01T04:15:19 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-01T04:15:19 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-01T04:15:19 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-01T04:15:19 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-01T04:15:19 (asr.sh:1451:main) Use ESPnet trainer
2026-01-01 04:15:19,693 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-01 04:15:19,729 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BC_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-01T09:17:32 (asr.sh:1842:main) Successfully finished. [elapsed=18134s]

✓ Model 26 (BC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 27/70: Training
==================================================================================
Block Structure: BCB
Module Config (list format): ['B','C','B']
Block Params (M): 1.170
Number of Blocks: 18
Total Params (M): 21.060
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'B']
  Applied to 18 blocks
YAML file updated successfully.
2026-01-01T09:17:32 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-01T09:17:32 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-01T09:17:32 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-01T09:17:32 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-01T09:17:32 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-01T09:17:32 (asr.sh:1451:main) Use ESPnet trainer
2026-01-01 09:17:32,770 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-01 09:17:32,786 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-01T22:40:08 (asr.sh:1842:main) Successfully finished. [elapsed=48156s]

✓ Model 27 (BCB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 28/70: Training
==================================================================================
Block Structure: BCBB
Module Config (list format): ['B','C','B','B']
Block Params (M): 1.652
Number of Blocks: 13
Total Params (M): 21.476
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'B', 'B']
  Applied to 13 blocks
YAML file updated successfully.
2026-01-01T22:40:08 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-01T22:40:08 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-01T22:40:08 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-01T22:40:08 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-01T22:40:08 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-01T22:40:08 (asr.sh:1451:main) Use ESPnet trainer
2026-01-01 22:40:08,870 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-01 22:40:08,886 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-02T13:00:47 (asr.sh:1842:main) Successfully finished. [elapsed=51639s]

✓ Model 28 (BCBB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 29/70: Training
==================================================================================
Block Structure: BCBBC
Module Config (list format): ['B','C','B','B','C']
Block Params (M): 1.858
Number of Blocks: 12
Total Params (M): 22.296
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'B', 'B', 'C']
  Applied to 12 blocks
YAML file updated successfully.
2026-01-02T13:00:47 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-02T13:00:47 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-02T13:00:47 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-02T13:00:47 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-02T13:00:47 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-02T13:00:47 (asr.sh:1451:main) Use ESPnet trainer
2026-01-02 13:00:47,647 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-02 13:00:47,663 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-02T23:42:31 (asr.sh:1842:main) Successfully finished. [elapsed=38504s]

✓ Model 29 (BCBBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 30/70: Training
==================================================================================
Block Structure: BCBBF
Module Config (list format): ['B','C','B','B','F']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'B', 'B', 'F']
  Applied to 10 blocks
YAML file updated successfully.
2026-01-02T23:42:32 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-02T23:42:32 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-02T23:42:32 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-02T23:42:32 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-02T23:42:32 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-02T23:42:32 (asr.sh:1451:main) Use ESPnet trainer
2026-01-02 23:42:32,376 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-02 23:42:32,392 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-03T08:57:18 (asr.sh:1842:main) Successfully finished. [elapsed=33286s]

✓ Model 30 (BCBBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 31/70: Training
==================================================================================
Block Structure: BCBCB
Module Config (list format): ['B','C','B','C','B']
Block Params (M): 1.858
Number of Blocks: 12
Total Params (M): 22.296
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'B', 'C', 'B']
  Applied to 12 blocks
YAML file updated successfully.
2026-01-03T08:57:18 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-03T08:57:18 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-03T08:57:18 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-03T08:57:18 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-03T08:57:18 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-03T08:57:18 (asr.sh:1451:main) Use ESPnet trainer
2026-01-03 08:57:18,939 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-03 08:57:18,955 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-03T23:13:40 (asr.sh:1842:main) Successfully finished. [elapsed=51382s]

✓ Model 31 (BCBCB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 32/70: Training
==================================================================================
Block Structure: BCBCF
Module Config (list format): ['B','C','B','C','F']
Block Params (M): 1.902
Number of Blocks: 11
Total Params (M): 20.922
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'B', 'C', 'F']
  Applied to 11 blocks
YAML file updated successfully.
2026-01-03T23:13:41 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-03T23:13:41 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-03T23:13:41 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-03T23:13:41 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-03T23:13:41 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-03T23:13:41 (asr.sh:1451:main) Use ESPnet trainer
2026-01-03 23:13:41,440 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-03 23:13:41,456 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-04T08:21:13 (asr.sh:1842:main) Successfully finished. [elapsed=32852s]

✓ Model 32 (BCBCF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 33/70: Training
==================================================================================
Block Structure: BCBF
Module Config (list format): ['B','C','B','F']
Block Params (M): 1.696
Number of Blocks: 13
Total Params (M): 22.048
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'B', 'F']
  Applied to 13 blocks
YAML file updated successfully.
2026-01-04T08:21:13 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-04T08:21:14 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-04T08:21:14 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-04T08:21:14 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-04T08:21:14 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-04T08:21:14 (asr.sh:1451:main) Use ESPnet trainer
2026-01-04 08:21:14,161 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-04 08:21:14,176 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-04T18:13:06 (asr.sh:1842:main) Successfully finished. [elapsed=35513s]

✓ Model 33 (BCBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 34/70: Training
==================================================================================
Block Structure: BCBFB
Module Config (list format): ['B','C','B','F','B']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'B', 'F', 'B']
  Applied to 10 blocks
YAML file updated successfully.
2026-01-04T18:13:06 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-04T18:13:07 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-04T18:13:07 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-04T18:13:07 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-04T18:13:07 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-04T18:13:07 (asr.sh:1451:main) Use ESPnet trainer
2026-01-04 18:13:07,144 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-04 18:13:07,161 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-05T09:07:06 (asr.sh:1842:main) Successfully finished. [elapsed=53640s]

✓ Model 34 (BCBFB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 35/70: Training
==================================================================================
Block Structure: BCBFC
Module Config (list format): ['B','C','B','F','C']
Block Params (M): 1.902
Number of Blocks: 11
Total Params (M): 20.922
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'B', 'F', 'C']
  Applied to 11 blocks
YAML file updated successfully.
2026-01-05T09:07:06 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-05T09:07:06 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-05T09:07:06 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-05T09:07:06 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-05T09:07:06 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-05T09:07:06 (asr.sh:1451:main) Use ESPnet trainer
2026-01-05 09:07:06,961 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-05 09:07:06,977 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFC_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-05T19:37:29 (asr.sh:1842:main) Successfully finished. [elapsed=37823s]

✓ Model 35 (BCBFC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 36/70: Training
==================================================================================
Block Structure: BCBFF
Module Config (list format): ['B','C','B','F','F']
Block Params (M): 2.222
Number of Blocks: 10
Total Params (M): 22.220
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'B', 'F', 'F']
  Applied to 10 blocks
YAML file updated successfully.
2026-01-05T19:37:29 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-05T19:37:30 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-05T19:37:30 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-05T19:37:30 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-05T19:37:30 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-05T19:37:30 (asr.sh:1451:main) Use ESPnet trainer
2026-01-05 19:37:30,131 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-05 19:37:30,148 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-06T06:26:11 (asr.sh:1842:main) Successfully finished. [elapsed=38922s]

✓ Model 36 (BCBFF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCBFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 37/70: Training
==================================================================================
Block Structure: BCF
Module Config (list format): ['B','C','F']
Block Params (M): 1.214
Number of Blocks: 18
Total Params (M): 21.852
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'F']
  Applied to 18 blocks
YAML file updated successfully.
2026-01-06T06:26:11 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-06T06:26:11 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-06T06:26:11 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-06T06:26:11 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-06T06:26:11 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-06T06:26:11 (asr.sh:1451:main) Use ESPnet trainer
2026-01-06 06:26:11,890 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-06 06:26:11,907 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-06T18:49:41 (asr.sh:1842:main) Successfully finished. [elapsed=44610s]

✓ Model 37 (BCF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 38/70: Training
==================================================================================
Block Structure: BCFB
Module Config (list format): ['B','C','F','B']
Block Params (M): 1.696
Number of Blocks: 13
Total Params (M): 22.048
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'F', 'B']
  Applied to 13 blocks
YAML file updated successfully.
2026-01-06T18:49:42 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-06T18:49:42 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-06T18:49:42 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-06T18:49:42 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-06T18:49:42 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-06T18:49:42 (asr.sh:1451:main) Use ESPnet trainer
2026-01-06 18:49:42,449 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-06 18:49:42,465 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-07T04:43:39 (asr.sh:1842:main) Successfully finished. [elapsed=35637s]

✓ Model 38 (BCFB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 39/70: Training
==================================================================================
Block Structure: BCFBB
Module Config (list format): ['B','C','F','B','B']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'F', 'B', 'B']
  Applied to 10 blocks
YAML file updated successfully.
2026-01-07T04:43:39 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-07T04:43:39 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-07T04:43:39 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-07T04:43:39 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-07T04:43:39 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-07T04:43:39 (asr.sh:1451:main) Use ESPnet trainer
2026-01-07 04:43:40,005 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-07 04:43:40,021 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-07T15:52:42 (asr.sh:1842:main) Successfully finished. [elapsed=40143s]

✓ Model 39 (BCFBB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 40/70: Training
==================================================================================
Block Structure: BCFBC
Module Config (list format): ['B','C','F','B','C']
Block Params (M): 1.902
Number of Blocks: 11
Total Params (M): 20.922
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'F', 'B', 'C']
  Applied to 11 blocks
YAML file updated successfully.
2026-01-07T15:52:42 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-07T15:52:42 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-07T15:52:42 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-07T15:52:42 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-07T15:52:42 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-07T15:52:42 (asr.sh:1451:main) Use ESPnet trainer
2026-01-07 15:52:42,843 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-07 15:52:42,860 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-08T01:32:21 (asr.sh:1842:main) Successfully finished. [elapsed=34779s]

✓ Model 40 (BCFBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 41/70: Training
==================================================================================
Block Structure: BCFBF
Module Config (list format): ['B','C','F','B','F']
Block Params (M): 2.222
Number of Blocks: 10
Total Params (M): 22.220
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'F', 'B', 'F']
  Applied to 10 blocks
YAML file updated successfully.
2026-01-08T01:32:22 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-08T01:32:22 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-08T01:32:22 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-08T01:32:22 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-08T01:32:22 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-08T01:32:22 (asr.sh:1451:main) Use ESPnet trainer
2026-01-08 01:32:22,402 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-08 01:32:22,418 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-08T09:50:48 (asr.sh:1842:main) Successfully finished. [elapsed=29906s]

✓ Model 41 (BCFBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 42/70: Training
==================================================================================
Block Structure: BCFC
Module Config (list format): ['B','C','F','C']
Block Params (M): 1.420
Number of Blocks: 15
Total Params (M): 21.300
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'F', 'C']
  Applied to 15 blocks
YAML file updated successfully.
2026-01-08T09:50:48 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-08T09:50:48 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-08T09:50:48 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-08T09:50:48 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-08T09:50:48 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-08T09:50:48 (asr.sh:1451:main) Use ESPnet trainer
2026-01-08 09:50:48,944 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-08 09:50:48,961 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFC_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-08T22:05:21 (asr.sh:1842:main) Successfully finished. [elapsed=44073s]

✓ Model 42 (BCFC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 43/70: Training
==================================================================================
Block Structure: BCFCB
Module Config (list format): ['B','C','F','C','B']
Block Params (M): 1.902
Number of Blocks: 11
Total Params (M): 20.922
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'F', 'C', 'B']
  Applied to 11 blocks
YAML file updated successfully.
2026-01-08T22:05:21 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-08T22:05:21 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-08T22:05:21 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-08T22:05:21 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-08T22:05:21 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-08T22:05:21 (asr.sh:1451:main) Use ESPnet trainer
2026-01-08 22:05:22,082 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-08 22:05:22,099 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-09T06:54:08 (asr.sh:1842:main) Successfully finished. [elapsed=31727s]

✓ Model 43 (BCFCB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 44/70: Training
==================================================================================
Block Structure: BCFCF
Module Config (list format): ['B','C','F','C','F']
Block Params (M): 1.946
Number of Blocks: 11
Total Params (M): 21.406
GPU: 0

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 0 (CUDA_VISIBLE_DEVICES=0)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'C', 'F', 'C', 'F']
  Applied to 11 blocks
YAML file updated successfully.
2026-01-09T06:54:08 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-09T06:54:09 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-09T06:54:09 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-09T06:54:09 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-09T06:54:09 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-09T06:54:09 (asr.sh:1451:main) Use ESPnet trainer
2026-01-09 06:54:09,150 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-09 06:54:09,166 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu0_BCFCF_asr_train_asr_raw_en_bpe1000_sp/train.log
