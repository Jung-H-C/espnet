nohup: ignoring input
==================================================================================
Training All Models from gpu_id_1_config.txt Sequentially
Using GPU 1
==================================================================================

Warning: Skipping line with empty num_blocks: Block   Params  N_of_Blocks Total_Params
==================================================================================
Model 71/141: Training
==================================================================================
Block Structure: BFFBB
Module Config (list format): ['B','F','F','B','B']
Block Params (M): 2.498
Number of Blocks: 9
Total Params (M): 22.482
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'F', 'F', 'B', 'B']
  Applied to 9 blocks
YAML file updated successfully.
2025-12-20T15:35:22 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-20T15:35:22 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-20T15:35:22 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-20T15:35:22 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-20T15:35:22 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-20T15:35:22 (asr.sh:1451:main) Use ESPnet trainer
2025-12-20 15:35:22,436 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-20 15:35:22,452 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-21T03:12:24 (asr.sh:1842:main) Successfully finished. [elapsed=41822s]

✓ Model 71 (BFFBB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 72/141: Training
==================================================================================
Block Structure: BFFBC
Module Config (list format): ['B','F','F','B','C']
Block Params (M): 2.222
Number of Blocks: 10
Total Params (M): 22.220
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'F', 'F', 'B', 'C']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-21T03:12:24 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-21T03:12:24 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-21T03:12:24 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-21T03:12:24 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-21T03:12:24 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-21T03:12:24 (asr.sh:1451:main) Use ESPnet trainer
2025-12-21 03:12:24,513 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-21 03:12:24,529 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-21T14:21:43 (asr.sh:1842:main) Successfully finished. [elapsed=40159s]

✓ Model 72 (BFFBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 73/141: Training
==================================================================================
Block Structure: BFFBF
Module Config (list format): ['B','F','F','B','F']
Block Params (M): 2.542
Number of Blocks: 8
Total Params (M): 20.336
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'F', 'F', 'B', 'F']
  Applied to 8 blocks
YAML file updated successfully.
2025-12-21T14:21:43 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-21T14:21:43 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-21T14:21:43 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-21T14:21:43 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-21T14:21:43 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-21T14:21:43 (asr.sh:1451:main) Use ESPnet trainer
2025-12-21 14:21:43,827 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-21 14:21:43,844 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-21T22:25:51 (asr.sh:1842:main) Successfully finished. [elapsed=29048s]

✓ Model 73 (BFFBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 74/141: Training
==================================================================================
Block Structure: BFFC
Module Config (list format): ['B','F','F','C']
Block Params (M): 1.740
Number of Blocks: 12
Total Params (M): 20.880
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'F', 'F', 'C']
  Applied to 12 blocks
YAML file updated successfully.
2025-12-21T22:25:51 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-21T22:25:51 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-21T22:25:51 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-21T22:25:51 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-21T22:25:51 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-21T22:25:51 (asr.sh:1451:main) Use ESPnet trainer
2025-12-21 22:25:52,046 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-21 22:25:52,062 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-22T08:12:38 (asr.sh:1842:main) Successfully finished. [elapsed=35207s]

✓ Model 74 (BFFC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 75/141: Training
==================================================================================
Block Structure: BFFCB
Module Config (list format): ['B','F','F','C','B']
Block Params (M): 2.222
Number of Blocks: 10
Total Params (M): 22.220
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'F', 'F', 'C', 'B']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-22T08:12:39 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-22T08:12:39 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-22T08:12:39 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-22T08:12:39 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-22T08:12:39 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-22T08:12:39 (asr.sh:1451:main) Use ESPnet trainer
2025-12-22 08:12:39,354 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-22 08:12:39,370 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-22T17:28:58 (asr.sh:1842:main) Successfully finished. [elapsed=33379s]

✓ Model 75 (BFFCB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 76/141: Training
==================================================================================
Block Structure: BFFCF
Module Config (list format): ['B','F','F','C','F']
Block Params (M): 2.266
Number of Blocks: 9
Total Params (M): 20.394
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'F', 'F', 'C', 'F']
  Applied to 9 blocks
YAML file updated successfully.
2025-12-22T17:28:58 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-22T17:28:58 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-22T17:28:58 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-22T17:28:58 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-22T17:28:58 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-22T17:28:58 (asr.sh:1451:main) Use ESPnet trainer
2025-12-22 17:28:58,477 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-22 17:28:58,494 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-23T01:24:04 (asr.sh:1842:main) Successfully finished. [elapsed=28506s]

✓ Model 76 (BFFCF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 77/141: Training
==================================================================================
Block Structure: BFFF
Module Config (list format): ['B','F','F','F']
Block Params (M): 2.060
Number of Blocks: 10
Total Params (M): 20.600
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'F', 'F', 'F']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-23T01:24:04 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-23T01:24:04 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-23T01:24:04 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-23T01:24:04 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-23T01:24:04 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-23T01:24:04 (asr.sh:1451:main) Use ESPnet trainer
2025-12-23 01:24:04,777 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-23 01:24:04,793 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-23T06:58:49 (asr.sh:1842:main) Successfully finished. [elapsed=20085s]

✓ Model 77 (BFFF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 78/141: Training
==================================================================================
Block Structure: BFFFB
Module Config (list format): ['B','F','F','F','B']
Block Params (M): 2.542
Number of Blocks: 8
Total Params (M): 20.336
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'F', 'F', 'F', 'B']
  Applied to 8 blocks
YAML file updated successfully.
2025-12-23T06:58:49 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-23T06:58:49 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-23T06:58:49 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-23T06:58:49 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-23T06:58:49 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-23T06:58:49 (asr.sh:1451:main) Use ESPnet trainer
2025-12-23 06:58:49,834 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-23 06:58:49,850 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-23T14:16:52 (asr.sh:1842:main) Successfully finished. [elapsed=26283s]

✓ Model 78 (BFFFB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 79/141: Training
==================================================================================
Block Structure: BFFFC
Module Config (list format): ['B','F','F','F','C']
Block Params (M): 2.266
Number of Blocks: 9
Total Params (M): 20.394
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'F', 'F', 'F', 'C']
  Applied to 9 blocks
YAML file updated successfully.
2025-12-23T14:16:53 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-23T14:16:53 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-23T14:16:53 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-23T14:16:53 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-23T14:16:53 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-23T14:16:53 (asr.sh:1451:main) Use ESPnet trainer
2025-12-23 14:16:53,419 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-23 14:16:53,436 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-23T17:18:45 (asr.sh:1842:main) Successfully finished. [elapsed=10912s]

✓ Model 79 (BFFFC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 5 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 80/141: Training
==================================================================================
Block Structure: BFFFF
Module Config (list format): ['B','F','F','F','F']
Block Params (M): 2.586
Number of Blocks: 8
Total Params (M): 20.688
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['B', 'F', 'F', 'F', 'F']
  Applied to 8 blocks
YAML file updated successfully.
2025-12-23T17:18:45 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-23T17:18:45 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-23T17:18:45 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-23T17:18:45 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-23T17:18:45 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-23T17:18:45 (asr.sh:1451:main) Use ESPnet trainer
2025-12-23 17:18:45,728 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-23 17:18:45,750 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-24T00:53:13 (asr.sh:1842:main) Successfully finished. [elapsed=27268s]

✓ Model 80 (BFFFF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_BFFFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 81/141: Training
==================================================================================
Block Structure: C
Module Config (list format): ['C']
Block Params (M): 0.206
Number of Blocks: 104
Total Params (M): 21.424
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_C_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C']
  Applied to 104 blocks
YAML file updated successfully.
2025-12-24T00:53:14 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_C_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-24T00:53:14 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-24T00:53:14 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-24T00:53:14 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_C_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-24T00:53:14 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_C_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-24T00:53:14 (asr.sh:1451:main) Use ESPnet trainer
2025-12-24 00:53:14,412 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_C_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_C_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_C_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_C_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-24 00:53:14,428 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_C_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-24T02:13:34 (asr.sh:1842:main) Successfully finished. [elapsed=4820s]

✓ Model 81 (C) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_C_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_C_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 82/141: Training
==================================================================================
Block Structure: CB
Module Config (list format): ['C','B']
Block Params (M): 0.688
Number of Blocks: 31
Total Params (M): 21.328
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B']
  Applied to 31 blocks
YAML file updated successfully.
2025-12-24T02:13:34 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-24T02:13:35 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-24T02:13:35 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-24T02:13:35 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-24T02:13:35 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-24T02:13:35 (asr.sh:1451:main) Use ESPnet trainer
2025-12-24 02:13:35,298 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-24 02:13:35,314 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-24T06:55:58 (asr.sh:1842:main) Successfully finished. [elapsed=16944s]

✓ Model 82 (CB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 83/141: Training
==================================================================================
Block Structure: CBB
Module Config (list format): ['C','B','B']
Block Params (M): 1.170
Number of Blocks: 18
Total Params (M): 21.060
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'B']
  Applied to 18 blocks
YAML file updated successfully.
2025-12-24T06:55:59 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-24T06:55:59 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-24T06:55:59 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-24T06:55:59 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-24T06:55:59 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-24T06:55:59 (asr.sh:1451:main) Use ESPnet trainer
2025-12-24 06:55:59,381 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-24 06:55:59,397 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-24T20:19:10 (asr.sh:1842:main) Successfully finished. [elapsed=48191s]

✓ Model 83 (CBB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 84/141: Training
==================================================================================
Block Structure: CBBB
Module Config (list format): ['C','B','B','B']
Block Params (M): 1.652
Number of Blocks: 13
Total Params (M): 21.476
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'B', 'B']
  Applied to 13 blocks
YAML file updated successfully.
2025-12-24T20:19:10 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-24T20:19:10 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-24T20:19:10 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-24T20:19:10 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-24T20:19:10 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-24T20:19:10 (asr.sh:1451:main) Use ESPnet trainer
2025-12-24 20:19:10,915 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-24 20:19:10,933 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-25T08:30:34 (asr.sh:1842:main) Successfully finished. [elapsed=43884s]

✓ Model 84 (CBBB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 85/141: Training
==================================================================================
Block Structure: CBBBC
Module Config (list format): ['C','B','B','B','C']
Block Params (M): 1.858
Number of Blocks: 12
Total Params (M): 22.296
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'B', 'B', 'C']
  Applied to 12 blocks
YAML file updated successfully.
2025-12-25T08:30:35 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-25T08:30:35 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-25T08:30:35 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-25T08:30:35 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-25T08:30:35 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-25T08:30:35 (asr.sh:1451:main) Use ESPnet trainer
2025-12-25 08:30:35,346 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-25 08:30:35,362 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-26T00:24:25 (asr.sh:1842:main) Successfully finished. [elapsed=57230s]

✓ Model 85 (CBBBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 86/141: Training
==================================================================================
Block Structure: CBBBF
Module Config (list format): ['C','B','B','B','F']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'B', 'B', 'F']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-26T00:24:25 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-26T00:24:25 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-26T00:24:25 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-26T00:24:25 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-26T00:24:25 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-26T00:24:25 (asr.sh:1451:main) Use ESPnet trainer
2025-12-26 00:24:25,600 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-26 00:24:25,616 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-26T12:10:47 (asr.sh:1842:main) Successfully finished. [elapsed=42382s]

✓ Model 86 (CBBBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 87/141: Training
==================================================================================
Block Structure: CBBC
Module Config (list format): ['C','B','B','C']
Block Params (M): 1.376
Number of Blocks: 16
Total Params (M): 22.016
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'B', 'C']
  Applied to 16 blocks
YAML file updated successfully.
2025-12-26T12:10:47 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-26T12:10:47 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-26T12:10:48 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-26T12:10:48 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-26T12:10:48 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-26T12:10:48 (asr.sh:1451:main) Use ESPnet trainer
2025-12-26 12:10:48,311 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-26 12:10:48,363 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-26T17:41:33 (asr.sh:1842:main) Successfully finished. [elapsed=19846s]

✓ Model 87 (CBBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 88/141: Training
==================================================================================
Block Structure: CBBCB
Module Config (list format): ['C','B','B','C','B']
Block Params (M): 1.858
Number of Blocks: 12
Total Params (M): 22.296
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'B', 'C', 'B']
  Applied to 12 blocks
YAML file updated successfully.
2025-12-26T17:41:33 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-26T17:41:34 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-26T17:41:34 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-26T17:41:35 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-26T17:41:35 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-26T17:41:35 (asr.sh:1451:main) Use ESPnet trainer
2025-12-26 17:41:35,158 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-26 17:41:35,181 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-27T06:12:56 (asr.sh:1842:main) Successfully finished. [elapsed=45083s]

✓ Model 88 (CBBCB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 89/141: Training
==================================================================================
Block Structure: CBBCF
Module Config (list format): ['C','B','B','C','F']
Block Params (M): 1.902
Number of Blocks: 11
Total Params (M): 20.922
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'B', 'C', 'F']
  Applied to 11 blocks
YAML file updated successfully.
2025-12-27T06:12:57 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-27T06:12:58 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-27T06:12:58 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-27T06:12:58 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-27T06:12:58 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-27T06:12:58 (asr.sh:1451:main) Use ESPnet trainer
2025-12-27 06:12:58,352 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-27 06:12:58,374 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-27T21:22:13 (asr.sh:1842:main) Successfully finished. [elapsed=54556s]

✓ Model 89 (CBBCF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 90/141: Training
==================================================================================
Block Structure: CBBF
Module Config (list format): ['C','B','B','F']
Block Params (M): 1.696
Number of Blocks: 13
Total Params (M): 22.048
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'B', 'F']
  Applied to 13 blocks
YAML file updated successfully.
2025-12-27T21:22:13 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-27T21:22:14 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-27T21:22:14 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-27T21:22:14 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-27T21:22:14 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-27T21:22:14 (asr.sh:1451:main) Use ESPnet trainer
2025-12-27 21:22:14,895 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-27 21:22:14,931 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-28T11:01:47 (asr.sh:1842:main) Successfully finished. [elapsed=49174s]

✓ Model 90 (CBBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 91/141: Training
==================================================================================
Block Structure: CBBFB
Module Config (list format): ['C','B','B','F','B']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'B', 'F', 'B']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-28T11:01:48 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-28T11:01:48 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-28T11:01:48 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-28T11:01:49 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-28T11:01:49 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-28T11:01:49 (asr.sh:1451:main) Use ESPnet trainer
2025-12-28 11:01:49,271 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-28 11:01:49,323 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-28T22:20:11 (asr.sh:1842:main) Successfully finished. [elapsed=40703s]

✓ Model 91 (CBBFB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 92/141: Training
==================================================================================
Block Structure: CBBFC
Module Config (list format): ['C','B','B','F','C']
Block Params (M): 1.902
Number of Blocks: 11
Total Params (M): 20.922
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'B', 'F', 'C']
  Applied to 11 blocks
YAML file updated successfully.
2025-12-28T22:20:11 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-28T22:20:12 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-28T22:20:12 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-28T22:20:12 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-28T22:20:12 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-28T22:20:12 (asr.sh:1451:main) Use ESPnet trainer
2025-12-28 22:20:12,265 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-28 22:20:12,292 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-29T13:57:01 (asr.sh:1842:main) Successfully finished. [elapsed=56210s]

✓ Model 92 (CBBFC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 93/141: Training
==================================================================================
Block Structure: CBBFF
Module Config (list format): ['C','B','B','F','F']
Block Params (M): 2.222
Number of Blocks: 10
Total Params (M): 22.220
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'B', 'F', 'F']
  Applied to 10 blocks
YAML file updated successfully.
2025-12-29T13:57:02 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-29T13:57:02 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-29T13:57:02 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-29T13:57:02 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-29T13:57:02 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-29T13:57:02 (asr.sh:1451:main) Use ESPnet trainer
2025-12-29 13:57:02,873 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-29 13:57:02,907 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-29T23:39:26 (asr.sh:1842:main) Successfully finished. [elapsed=34944s]

✓ Model 93 (CBBFF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBBFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 94/141: Training
==================================================================================
Block Structure: CBC
Module Config (list format): ['C','B','C']
Block Params (M): 0.894
Number of Blocks: 24
Total Params (M): 21.456
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'C']
  Applied to 24 blocks
YAML file updated successfully.
2025-12-29T23:39:26 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-29T23:39:27 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-29T23:39:27 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-29T23:39:27 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-29T23:39:27 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-29T23:39:27 (asr.sh:1451:main) Use ESPnet trainer
2025-12-29 23:39:27,808 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-29 23:39:27,830 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-30T04:42:41 (asr.sh:1842:main) Successfully finished. [elapsed=18195s]

✓ Model 94 (CBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 95/141: Training
==================================================================================
Block Structure: CBCBB
Module Config (list format): ['C','B','C','B','B']
Block Params (M): 1.858
Number of Blocks: 12
Total Params (M): 22.296
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'C', 'B', 'B']
  Applied to 12 blocks
YAML file updated successfully.
2025-12-30T04:42:41 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-30T04:42:42 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-30T04:42:42 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-30T04:42:42 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-30T04:42:42 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-30T04:42:42 (asr.sh:1451:main) Use ESPnet trainer
2025-12-30 04:42:42,349 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-30 04:42:42,371 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBB_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-30T22:25:34 (asr.sh:1842:main) Successfully finished. [elapsed=63773s]

✓ Model 95 (CBCBB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 96/141: Training
==================================================================================
Block Structure: CBCBC
Module Config (list format): ['C','B','C','B','C']
Block Params (M): 1.582
Number of Blocks: 14
Total Params (M): 22.148
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'C', 'B', 'C']
  Applied to 14 blocks
YAML file updated successfully.
2025-12-30T22:25:34 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-30T22:25:35 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-30T22:25:35 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-30T22:25:35 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-30T22:25:35 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-30T22:25:35 (asr.sh:1451:main) Use ESPnet trainer
2025-12-30 22:25:35,781 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-30 22:25:35,803 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-31T04:08:51 (asr.sh:1842:main) Successfully finished. [elapsed=20597s]

✓ Model 96 (CBCBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 97/141: Training
==================================================================================
Block Structure: CBCBF
Module Config (list format): ['C','B','C','B','F']
Block Params (M): 1.902
Number of Blocks: 11
Total Params (M): 20.922
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'C', 'B', 'F']
  Applied to 11 blocks
YAML file updated successfully.
2025-12-31T04:08:52 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-31T04:08:53 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-31T04:08:53 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-31T04:08:53 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-31T04:08:53 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-31T04:08:53 (asr.sh:1451:main) Use ESPnet trainer
2025-12-31 04:08:53,245 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-31 04:08:53,311 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2025-12-31T15:48:11 (asr.sh:1842:main) Successfully finished. [elapsed=41959s]

✓ Model 97 (CBCBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 98/141: Training
==================================================================================
Block Structure: CBCF
Module Config (list format): ['C','B','C','F']
Block Params (M): 1.420
Number of Blocks: 15
Total Params (M): 21.300
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'C', 'F']
  Applied to 15 blocks
YAML file updated successfully.
2025-12-31T15:48:11 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2025-12-31T15:48:12 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2025-12-31T15:48:12 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2025-12-31T15:48:12 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2025-12-31T15:48:12 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2025-12-31T15:48:12 (asr.sh:1451:main) Use ESPnet trainer
2025-12-31 15:48:12,839 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2025-12-31 15:48:12,879 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-01T04:11:09 (asr.sh:1842:main) Successfully finished. [elapsed=44578s]

✓ Model 98 (CBCF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 99/141: Training
==================================================================================
Block Structure: CBCFB
Module Config (list format): ['C','B','C','F','B']
Block Params (M): 1.902
Number of Blocks: 11
Total Params (M): 20.922
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'C', 'F', 'B']
  Applied to 11 blocks
YAML file updated successfully.
2026-01-01T04:11:10 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-01T04:11:10 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-01T04:11:10 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-01T04:11:10 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-01T04:11:10 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-01T04:11:10 (asr.sh:1451:main) Use ESPnet trainer
2026-01-01 04:11:11,157 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-01 04:11:11,195 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-01T15:24:54 (asr.sh:1842:main) Successfully finished. [elapsed=40424s]

✓ Model 99 (CBCFB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 100/141: Training
==================================================================================
Block Structure: CBCFC
Module Config (list format): ['C','B','C','F','C']
Block Params (M): 1.626
Number of Blocks: 13
Total Params (M): 21.138
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'C', 'F', 'C']
  Applied to 13 blocks
YAML file updated successfully.
2026-01-01T15:24:54 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-01T15:24:54 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-01T15:24:54 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-01T15:24:54 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-01T15:24:54 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-01T15:24:54 (asr.sh:1451:main) Use ESPnet trainer
2026-01-01 15:24:55,102 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-01 15:24:55,118 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFC_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-02T01:02:56 (asr.sh:1842:main) Successfully finished. [elapsed=34682s]

✓ Model 100 (CBCFC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 101/141: Training
==================================================================================
Block Structure: CBCFF
Module Config (list format): ['C','B','C','F','F']
Block Params (M): 1.946
Number of Blocks: 11
Total Params (M): 21.406
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'C', 'F', 'F']
  Applied to 11 blocks
YAML file updated successfully.
2026-01-02T01:02:56 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-02T01:02:56 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-02T01:02:56 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-02T01:02:56 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-02T01:02:56 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-02T01:02:56 (asr.sh:1451:main) Use ESPnet trainer
2026-01-02 01:02:56,664 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-02 01:02:56,681 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-02T11:14:41 (asr.sh:1842:main) Successfully finished. [elapsed=36705s]

✓ Model 101 (CBCFF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBCFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 102/141: Training
==================================================================================
Block Structure: CBF
Module Config (list format): ['C','B','F']
Block Params (M): 1.214
Number of Blocks: 18
Total Params (M): 21.852
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'F']
  Applied to 18 blocks
YAML file updated successfully.
2026-01-02T11:14:41 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-02T11:14:41 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-02T11:14:41 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-02T11:14:41 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-02T11:14:41 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-02T11:14:41 (asr.sh:1451:main) Use ESPnet trainer
2026-01-02 11:14:41,816 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-02 11:14:41,832 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-02T20:15:41 (asr.sh:1842:main) Successfully finished. [elapsed=32460s]

✓ Model 102 (CBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 103/141: Training
==================================================================================
Block Structure: CBFB
Module Config (list format): ['C','B','F','B']
Block Params (M): 1.696
Number of Blocks: 13
Total Params (M): 22.048
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'F', 'B']
  Applied to 13 blocks
YAML file updated successfully.
2026-01-02T20:15:41 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-02T20:15:41 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-02T20:15:41 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-02T20:15:41 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-02T20:15:41 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-02T20:15:41 (asr.sh:1451:main) Use ESPnet trainer
2026-01-02 20:15:41,690 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-02 20:15:41,707 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-03T10:58:04 (asr.sh:1842:main) Successfully finished. [elapsed=52943s]

✓ Model 103 (CBFB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 104/141: Training
==================================================================================
Block Structure: CBFBB
Module Config (list format): ['C','B','F','B','B']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'F', 'B', 'B']
  Applied to 10 blocks
YAML file updated successfully.
2026-01-03T10:58:04 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-03T10:58:04 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-03T10:58:04 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-03T10:58:04 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-03T10:58:04 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-03T10:58:04 (asr.sh:1451:main) Use ESPnet trainer
2026-01-03 10:58:04,830 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-03 10:58:04,846 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-03T22:39:01 (asr.sh:1842:main) Successfully finished. [elapsed=42057s]

✓ Model 104 (CBFBB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 105/141: Training
==================================================================================
Block Structure: CBFBC
Module Config (list format): ['C','B','F','B','C']
Block Params (M): 1.902
Number of Blocks: 11
Total Params (M): 20.922
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'F', 'B', 'C']
  Applied to 11 blocks
YAML file updated successfully.
2026-01-03T22:39:01 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-03T22:39:01 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-03T22:39:01 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-03T22:39:01 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-03T22:39:01 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-03T22:39:01 (asr.sh:1451:main) Use ESPnet trainer
2026-01-03 22:39:01,724 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-03 22:39:01,740 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-04T07:46:51 (asr.sh:1842:main) Successfully finished. [elapsed=32870s]

✓ Model 105 (CBFBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 106/141: Training
==================================================================================
Block Structure: CBFBF
Module Config (list format): ['C','B','F','B','F']
Block Params (M): 2.222
Number of Blocks: 10
Total Params (M): 22.220
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'F', 'B', 'F']
  Applied to 10 blocks
YAML file updated successfully.
2026-01-04T07:46:51 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-04T07:46:51 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-04T07:46:51 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-04T07:46:51 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-04T07:46:51 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-04T07:46:51 (asr.sh:1451:main) Use ESPnet trainer
2026-01-04 07:46:52,105 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-04 07:46:52,121 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-04T19:50:23 (asr.sh:1842:main) Successfully finished. [elapsed=43412s]

✓ Model 106 (CBFBF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFBF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 107/141: Training
==================================================================================
Block Structure: CBFC
Module Config (list format): ['C','B','F','C']
Block Params (M): 1.420
Number of Blocks: 15
Total Params (M): 21.300
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'F', 'C']
  Applied to 15 blocks
YAML file updated successfully.
2026-01-04T19:50:23 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-04T19:50:24 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-04T19:50:24 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-04T19:50:24 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-04T19:50:24 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-04T19:50:24 (asr.sh:1451:main) Use ESPnet trainer
2026-01-04 19:50:24,174 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-04 19:50:24,191 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFC_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-05T03:56:20 (asr.sh:1842:main) Successfully finished. [elapsed=29157s]

✓ Model 107 (CBFC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 108/141: Training
==================================================================================
Block Structure: CBFCB
Module Config (list format): ['C','B','F','C','B']
Block Params (M): 1.902
Number of Blocks: 11
Total Params (M): 20.922
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'F', 'C', 'B']
  Applied to 11 blocks
YAML file updated successfully.
2026-01-05T03:56:20 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-05T03:56:20 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-05T03:56:20 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-05T03:56:20 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-05T03:56:20 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-05T03:56:20 (asr.sh:1451:main) Use ESPnet trainer
2026-01-05 03:56:21,025 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-05 03:56:21,042 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-05T13:04:08 (asr.sh:1842:main) Successfully finished. [elapsed=32868s]

✓ Model 108 (CBFCB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 109/141: Training
==================================================================================
Block Structure: CBFCF
Module Config (list format): ['C','B','F','C','F']
Block Params (M): 1.946
Number of Blocks: 11
Total Params (M): 21.406
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'F', 'C', 'F']
  Applied to 11 blocks
YAML file updated successfully.
2026-01-05T13:04:08 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-05T13:04:08 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-05T13:04:08 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-05T13:04:08 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-05T13:04:08 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-05T13:04:08 (asr.sh:1451:main) Use ESPnet trainer
2026-01-05 13:04:09,061 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-05 13:04:09,077 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-05T18:51:22 (asr.sh:1842:main) Successfully finished. [elapsed=20834s]

✓ Model 109 (CBFCF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFCF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 110/141: Training
==================================================================================
Block Structure: CBFF
Module Config (list format): ['C','B','F','F']
Block Params (M): 1.740
Number of Blocks: 12
Total Params (M): 20.880
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'F', 'F']
  Applied to 12 blocks
YAML file updated successfully.
2026-01-05T18:51:22 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-05T18:51:22 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-05T18:51:22 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-05T18:51:22 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-05T18:51:22 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-05T18:51:22 (asr.sh:1451:main) Use ESPnet trainer
2026-01-05 18:51:22,621 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-05 18:51:22,638 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-06T05:07:23 (asr.sh:1842:main) Successfully finished. [elapsed=36961s]

✓ Model 110 (CBFF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 111/141: Training
==================================================================================
Block Structure: CBFFB
Module Config (list format): ['C','B','F','F','B']
Block Params (M): 2.222
Number of Blocks: 10
Total Params (M): 22.220
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'F', 'F', 'B']
  Applied to 10 blocks
YAML file updated successfully.
2026-01-06T05:07:23 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-06T05:07:24 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-06T05:07:24 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-06T05:07:24 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-06T05:07:24 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-06T05:07:24 (asr.sh:1451:main) Use ESPnet trainer
2026-01-06 05:07:24,211 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-06 05:07:24,228 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-06T13:45:04 (asr.sh:1842:main) Successfully finished. [elapsed=31061s]

✓ Model 111 (CBFFB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 112/141: Training
==================================================================================
Block Structure: CBFFC
Module Config (list format): ['C','B','F','F','C']
Block Params (M): 1.946
Number of Blocks: 11
Total Params (M): 21.406
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'F', 'F', 'C']
  Applied to 11 blocks
YAML file updated successfully.
2026-01-06T13:45:04 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-06T13:45:04 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-06T13:45:04 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-06T13:45:04 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-06T13:45:04 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-06T13:45:04 (asr.sh:1451:main) Use ESPnet trainer
2026-01-06 13:45:04,625 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-06 13:45:04,642 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFC_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-06T22:02:48 (asr.sh:1842:main) Successfully finished. [elapsed=29864s]

✓ Model 112 (CBFFC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 113/141: Training
==================================================================================
Block Structure: CBFFF
Module Config (list format): ['C','B','F','F','F']
Block Params (M): 2.266
Number of Blocks: 9
Total Params (M): 20.394
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'B', 'F', 'F', 'F']
  Applied to 9 blocks
YAML file updated successfully.
2026-01-06T22:02:48 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-06T22:02:49 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-06T22:02:49 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-06T22:02:49 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-06T22:02:49 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-06T22:02:49 (asr.sh:1451:main) Use ESPnet trainer
2026-01-06 22:02:49,235 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-06 22:02:49,251 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-07T04:33:34 (asr.sh:1842:main) Successfully finished. [elapsed=23446s]

✓ Model 113 (CBFFF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CBFFF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 114/141: Training
==================================================================================
Block Structure: CF
Module Config (list format): ['C','F']
Block Params (M): 0.732
Number of Blocks: 29
Total Params (M): 21.228
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'F']
  Applied to 29 blocks
YAML file updated successfully.
2026-01-07T04:33:35 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-07T04:33:35 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-07T04:33:35 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-07T04:33:35 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-07T04:33:35 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-07T04:33:35 (asr.sh:1451:main) Use ESPnet trainer
2026-01-07 04:33:35,377 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-07 04:33:35,394 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CF_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-07T12:13:22 (asr.sh:1842:main) Successfully finished. [elapsed=27587s]

✓ Model 114 (CF) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CF_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 115/141: Training
==================================================================================
Block Structure: CFB
Module Config (list format): ['C','F','B']
Block Params (M): 1.214
Number of Blocks: 18
Total Params (M): 21.852
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'F', 'B']
  Applied to 18 blocks
YAML file updated successfully.
2026-01-07T12:13:22 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-07T12:13:22 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-07T12:13:22 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-07T12:13:22 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-07T12:13:22 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-07T12:13:22 (asr.sh:1451:main) Use ESPnet trainer
2026-01-07 12:13:23,057 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-07 12:13:23,073 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-08T00:55:31 (asr.sh:1842:main) Successfully finished. [elapsed=45729s]

✓ Model 115 (CFB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 7 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 116/141: Training
==================================================================================
Block Structure: CFBB
Module Config (list format): ['C','F','B','B']
Block Params (M): 1.696
Number of Blocks: 13
Total Params (M): 22.048
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'F', 'B', 'B']
  Applied to 13 blocks
YAML file updated successfully.
2026-01-08T00:55:32 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-08T00:55:32 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-08T00:55:32 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-08T00:55:32 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-08T00:55:32 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-08T00:55:32 (asr.sh:1451:main) Use ESPnet trainer
2026-01-08 00:55:32,458 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-08 00:55:32,475 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-08T10:27:06 (asr.sh:1842:main) Successfully finished. [elapsed=34294s]

✓ Model 116 (CFBB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 117/141: Training
==================================================================================
Block Structure: CFBBB
Module Config (list format): ['C','F','B','B','B']
Block Params (M): 2.178
Number of Blocks: 10
Total Params (M): 21.780
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBB_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'F', 'B', 'B', 'B']
  Applied to 10 blocks
YAML file updated successfully.
2026-01-08T10:27:07 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBB_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-08T10:27:07 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-08T10:27:07 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-08T10:27:07 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBB_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-08T10:27:07 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBB_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-08T10:27:07 (asr.sh:1451:main) Use ESPnet trainer
2026-01-08 10:27:07,347 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBB_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBB_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBB_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBB_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-08 10:27:07,363 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBB_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-08T22:21:07 (asr.sh:1842:main) Successfully finished. [elapsed=42840s]

✓ Model 117 (CFBBB) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBB_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 118/141: Training
==================================================================================
Block Structure: CFBBC
Module Config (list format): ['C','F','B','B','C']
Block Params (M): 1.902
Number of Blocks: 11
Total Params (M): 20.922
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBC_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'F', 'B', 'B', 'C']
  Applied to 11 blocks
YAML file updated successfully.
2026-01-08T22:21:07 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBC_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-08T22:21:08 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-08T22:21:08 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-08T22:21:08 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBC_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-08T22:21:08 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBC_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-08T22:21:08 (asr.sh:1451:main) Use ESPnet trainer
2026-01-08 22:21:08,215 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBC_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBC_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBC_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBC_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-08 22:21:08,231 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBC_asr_train_asr_raw_en_bpe1000_sp/train.log
2026-01-09T09:14:23 (asr.sh:1842:main) Successfully finished. [elapsed=39196s]

✓ Model 118 (CFBBC) training completed successfully
✓ Checkpoint saved: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth
✓ Removed 6 .pth file(s) (kept /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBC_asr_train_asr_raw_en_bpe1000_sp/valid.cer_ctc.ave_5best.pth, 10epoch.pth, 25epoch.pth)

==================================================================================

==================================================================================
Model 119/141: Training
==================================================================================
Block Structure: CFBBF
Module Config (list format): ['C','F','B','B','F']
Block Params (M): 2.222
Number of Blocks: 10
Total Params (M): 22.220
GPU: 1

Starting training...
Experiment directory: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBF_asr_train_asr_raw_en_bpe1000_sp

Using GPU: 1 (CUDA_VISIBLE_DEVICES=1)
Updating module_config in conf/train_asr.yaml...
Updated conf/train_asr.yaml with module_config:
  Configuration: ['C', 'F', 'B', 'B', 'F']
  Applied to 10 blocks
YAML file updated successfully.
2026-01-09T09:14:23 (asr.sh:285:main) ./asr.sh --lang en --ngpu 1 --nj 16 --gpu_inference true --inference_nj 6 --nbpe 5000 --max_wav_duration 30 --audio_format flac.ark --speed_perturb_factors 0.9 1.0 1.1 --feats_type raw --use_lm false --asr_config conf/train_asr.yaml --inference_config conf/decode_asr.yaml --train_set train_clean_100 --valid_set dev --test_sets test_clean test_other --inference_asr_model valid.cer_ctc.ave_5best.pth --lm_train_text data/train_clean_100/text --bpe_train_text data/train_clean_100/text --asr_exp /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBF_asr_train_asr_raw_en_bpe1000_sp --stage 11 --stop_stage 11
2026-01-09T09:14:23 (asr.sh:566:main) Skipped stages:  6 7 8 9 14 15 
2026-01-09T09:14:23 (asr.sh:1310:main) Stage 11: ASR Training: train_set=dump/raw/train_clean_100_sp, valid_set=dump/raw/dev
2026-01-09T09:14:23 (asr.sh:1409:main) Generate '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBF_asr_train_asr_raw_en_bpe1000_sp/run.sh'. You can resume the process from stage 11 using this script
2026-01-09T09:14:23 (asr.sh:1413:main) ASR training started... log: '/home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBF_asr_train_asr_raw_en_bpe1000_sp/train.log'
2026-01-09T09:14:23 (asr.sh:1451:main) Use ESPnet trainer
2026-01-09 09:14:23,843 (launch:94) INFO: /home/gpuadmin/anaconda3/envs/junghc/bin/python3 /home/gpuadmin/espnet/espnet2/bin/launch.py --cmd 'run.pl --name /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBF_asr_train_asr_raw_en_bpe1000_sp/train.log' --log /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBF_asr_train_asr_raw_en_bpe1000_sp/train.log --ngpu 1 --num_nodes 1 --init_file_prefix /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBF_asr_train_asr_raw_en_bpe1000_sp/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel data/en_token_list/bpe_bpe5000/bpe.model --token_type bpe --token_list data/en_token_list/bpe_bpe5000/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,kaldi_ark --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBF_asr_train_asr_raw_en_bpe1000_sp --config conf/train_asr.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_bpe5000_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/wav.scp,speech,kaldi_ark --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_clean_100_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_bpe5000_sp/train/text_shape.bpe --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_bpe5000_sp/valid/text_shape.bpe
2026-01-09 09:14:23,859 (launch:348) INFO: log file: /home/gpuadmin/espnet/egs2/librispeech_100/mamba_practice_asr1/exp/gpu1_CFBBF_asr_train_asr_raw_en_bpe1000_sp/train.log
